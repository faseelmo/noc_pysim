from enum           import Enum
from dataclasses    import dataclass 
from typing         import Optional, Union

from .packet        import Packet
from .buffer        import Buffer
from .flit          import HeaderFlit, PayloadFlit, TailFlit


class TaskStatus(Enum):
    IDLE        =   "idle"         # idle (waiting for packets)
    PROCESSING  =   "processing"   # computing
    DONE        =   "done"         # done processing
    IN_BUFFER   =   "in_buffer"    # in the buffer 


@dataclass
class TaskDependency:
    require_id:     int # Task id of the task that requires the packets
    generate_id:    int # Task id of the task that generates the packets


@dataclass
class RequireInfo:
    require_type_id:        int
    required_packets:       int
    received_packet_count:  int = 0

@dataclass
class TransmitInfo: 
    id:         int
    require:    int 
    count:      int = 0

@dataclass
class TaskInfo:
    task_id:                    int 
    processing_cycles:          int
    expected_generated_packets: int                 # number of packets to generate (constant)
    require_list :              list[RequireInfo]   
    current_processing_cycle:   int         = 0     
    generated_packet_count:     int         = 0     # number of packets generated (incremented)
    sent_generated_packets:     int         = 0     # for packets required by other task in the same PE
    status:                     TaskStatus  = TaskStatus.IDLE
    start_cycle:                int         = None
    end_cycle:                  int         = None

    is_transmit_task:           bool                = False # Final node in the graph assigned to this PE
    transmit_list:              list[TransmitInfo]  = None  # List of task ids that require the packets generated by this task


class ProcessingElement:
    def __init__(
            self, 
            xy                  : tuple [int, int], 
            computing_list      : list  [TaskInfo]  = None, 
            debug_mode          : bool              = False, 
            shortest_job_first  : bool              = False, 
            router_lookup       : dict              = None
        ):

        self.xy                         = xy 
        self.compute_list               = computing_list
        self.compute_is_busy            = False
        self.shortest_job_first         = shortest_job_first    
        self.debug_mode                 = debug_mode
        self.current_processing_cycle   = 0   # Might have to move this to instantiation later
        self.router_lookup              = router_lookup

        self.current_id_transmitted_count = 0

        self.input_network_interface    = Buffer(size=4, name= f"NI[Input]")
        self.output_network_interface   = Buffer(size=4, name= f"NI[Output]")
        
        if self.compute_list is not None:
            self.required_packet_types  = self._get_unique_required_packet_type()

    def clear(self) -> None:
        self.compute_list = None
        self.compute_is_busy = False
        self.current_processing_cycle = 0
        self.input_network_interface.clear()
        self.output_network_interface.clear()
        self.current_id_transmitted_count = 0
        self.required_packet_types = None

    def assign_task(self, computing_list: list [ TaskInfo ]) -> None:
        if self.compute_list is not None:
            self.compute_list.extend(computing_list)
        else: 
            self.compute_list = computing_list
        self.required_packet_types = self._get_unique_required_packet_type()

    def _debug_print(self, string: str, with_tag: bool = True) -> None: 

        if self.debug_mode:
            if with_tag:
                print(f"{self}{string}")
            else:
                print(string)

    def _increment_processing_cycle(self) -> None:
        """Increments the processing cycle for the PE"""
        self.current_processing_cycle += 1

    def _get_unique_required_packet_type(self) -> list[int]:

        packet_type_list = []

        for compute_task in self.compute_list: 
            for require in compute_task.require_list:
                if require.require_type_id not in packet_type_list:
                    packet_type_list.append(require.require_type_id)

        self._debug_print(f"Unique packet types required in this PE: {packet_type_list}")

        return packet_type_list


    def _update_TaskInfo(self, task_id: int) -> None:
        """ 
        - Increment received_packet_count for all the tasks that require the packet  
        - If this behavior is not desired, that is all the tasks that require getting their 
            copy of packet (having a cache in PE) the function can be modified by returning 
            after the first increment. Uncomment the return statement.
        """

        for compute_task in self.compute_list:
            for require in compute_task.require_list:

                if require.required_packets == require.received_packet_count:
                    # skipping if required packets have been received
                    continue

                if require.require_type_id == task_id:
                    require.received_packet_count += 1
                    # return

        if self.debug_mode:
            self._get_packet_count()

    def _recieve_packets(self, packet: Packet) -> None:
        """
        Checks if the packet received is required by the PE
        Updates the packet status and location  
        """
        packet_source_task_id = packet.get_source_task_id()

        if packet_source_task_id not in self.required_packet_types:
            raise ValueError(f"Packet type {packet_source_task_id} not required in this PE")

        packet.increment_flits()
        self._debug_print(f"Recieving flits (type: {packet_source_task_id}) {packet.get_flits_transmitted_count()}/{packet.get_size()}")
        is_transmitted, recieved_packet_task_id = packet.check_transmission_status()
        
        if is_transmitted:
            self._update_TaskInfo(recieved_packet_task_id)

    def receive_flits(self, flit: Union[HeaderFlit, PayloadFlit, TailFlit] ) -> None:
        """
        Receving flits from the network interface. 
        When the 
        This function should be called from a router. 
        """
        flit_source_id = flit.get_source_task_id()

        if flit_source_id not in self.required_packet_types:
            raise ValueError( f"Flit type {flit_source_id} not required in this PE" )

        self.input_network_interface.add_flit(flit)

        self._debug_print(f"Recieving flits (type: {flit_source_id})")
        self._debug_print(f"\t-> {self.input_network_interface}", with_tag=False)

        if isinstance(flit, TailFlit):
            self._update_TaskInfo( flit_source_id )
            self.input_network_interface.empty()
            self._debug_print(f"Packet fully recieved. Emptying the input buffer")

    def _reset_received_packet_task(self, compute_task: TaskInfo) -> None:
        """
        Resets the current processing cycle to 0
        """
        for require in compute_task.require_list:
            require.received_packet_count = 0

    def _can_start_new_processing(self) -> None:
        """
        Checks if all the required packets for a task have been received
            Processing can only start if all required packets (w/ task_id) have been received
            > Room for optimization here
        Also does scheduling based on the number of required packets. 
        Priority is given to the task that requires the least number of packets. 
        """

        tasks_ready_to_execute = []
        
        for compute_task in self.compute_list:
            readiness_check     = []

            require_list_len    = len(compute_task.require_list)


            if compute_task.expected_generated_packets ==  compute_task.generated_packet_count:
                # if task has generated the expected count of packets
                continue

            total_require_count = 0  # for scheduling
            for require in compute_task.require_list:
                total_require_count += require.required_packets
                if compute_task.status is TaskStatus.IDLE:
                    if require.received_packet_count == require.required_packets:
                        readiness_check.append(True)

            if len(readiness_check) == require_list_len:

                if self.shortest_job_first:
                    # For Shortest Job First Scheduling
                    tasks_ready_to_execute.append( (total_require_count, compute_task) ) 

                else:
                    # Randomly scheduling the task for processing
                    compute_task.status         = TaskStatus.PROCESSING
                    compute_task.start_cycle    = self.current_processing_cycle

                    self.compute_is_busy = True
                    self._reset_received_packet_task(compute_task)
                    self._debug_print(f"Scheduling (random) task {compute_task.task_id} for processing")

                    return 

        # Shortest Job First Scheduling 
        if self.shortest_job_first and  tasks_ready_to_execute:

            execute_task = min(tasks_ready_to_execute, key=lambda x: x[0])[1]
            execute_task.status = TaskStatus.PROCESSING 
            execute_task.start_cycle = self.current_processing_cycle

            if self.debug_mode:
                debug_tasks_ready_to_execute = [(task_info.task_id, count) for count, task_info in tasks_ready_to_execute]
                self._debug_print(f"Tasks ready to execute (id, require count): {debug_tasks_ready_to_execute}")

            self.compute_is_busy = True
            self._reset_received_packet_task(execute_task)
            self._debug_print(f"Scheduling (SJF) task {execute_task.task_id} for processing")


    def _update_task_as_complete(self, compute_task: TaskInfo) -> None:
        """
        Task is marked as done when the expected number of packets have been generated
        """
        compute_task.status     = TaskStatus.DONE
        compute_task.end_cycle  = self.current_processing_cycle
        self.compute_is_busy    = False

    
    def _check_generate_for_inter_task_dependency(self, current_task: TaskInfo) -> None:  
        """
        Check if the generated packets are required by other tasks in the same PE 
        """
    
        for task_in_compute_list in self.compute_list:
            # Incrementing the count of received packets 
            #   if the generated packets are required by a 
            #   different Task in the same PE
            for require in task_in_compute_list.require_list:

                if require.required_packets == require.received_packet_count:
                    continue

                if require.require_type_id == current_task.task_id:

                    require.received_packet_count += 1
                    self._debug_print(
                        f"Task {task_in_compute_list.task_id} has received {require.received_packet_count}/{require.required_packets} "
                        f"packets of type {require.require_type_id}")

                    return 

    def _process_compute_task(self, compute_task: TaskInfo) -> None:
        """
        Tasks generate packets here  

        For transmit tasks, the packets are sent to the output buffer
        if the output buffer is full, the task will wait until the output buffer is free

        Redundant code here, can be made more efficient. 
        Im sorry for the mess.

        I'll try to explain what's happening here:

        So, for normal task (non terminal node), the second condition is executed.
        just look at the PROCESSING condition. Easy peasy.
        
        For transmit tasks(which is the last task assgined to the PE) 
        when the packet is generated, it is sent to the output buffer. 

        Here's the tricky part, when this task create more packets, we have to check if 
        the output buffer is empty. 
        If it is not empty, there is back pressure on the PE. 
        So any further compute will have to wait until the output buffer is empty.

        Hope this makes sense. xo for reading this.
        """

        if compute_task.status is TaskStatus.IN_BUFFER: 

            # Check if the PE output buffer has been emptied 
            is_buffer_empty = self.output_network_interface.is_empty()

            if not is_buffer_empty:
                # If there are flits in the output buffer
                                
                if self.router_lookup is not None: # For testing router_lookup is None
                    is_packet_moved = self._move_flits_to_router_buffer()

                    if is_packet_moved:
                        is_buffer_empty = True
                        compute_task.generated_packet_count += 1    
                        self._debug_print(
                            f"Generated {compute_task.generated_packet_count}/{compute_task.expected_generated_packets} " 
                            f"packets of task id {compute_task.task_id}"
                        )

            if is_buffer_empty:
                # Packer already sent to the output buffer
                # Below are the things to do after that

                if compute_task.generated_packet_count < compute_task.expected_generated_packets:
                    # If total generate count is not achieved, continue generating packets (PROCESSING)
                    compute_task.current_processing_cycle   = 0 
                    compute_task.status                     = TaskStatus.PROCESSING
                
                elif compute_task.generated_packet_count == compute_task.expected_generated_packets:
                    # If all the required packets are generated, mark the task as done.  
                    # Processor is DONE. 
                    self._update_task_as_complete(compute_task)

                else:
                    raise ValueError("Generated packet count is greater than expected generated packets")

            else:
                self._debug_print(f"NI[Output] is occupied, Cannot generate packets.")


        if compute_task.status is TaskStatus.PROCESSING:
            # Second condition 

            compute_task.current_processing_cycle += 1  

            if compute_task.current_processing_cycle == compute_task.processing_cycles:

                self._debug_print(
                    f"Task {compute_task.task_id} is done processing "
                    f"{compute_task.current_processing_cycle}/{compute_task.processing_cycles}"
                )

                if compute_task.is_transmit_task:
                    # If 'task' is the last task in the PE
                    # Generate count is incremented when the 
                    # packet is fully moved to the PE local input buffer. 
                    self._process_trasmit_generate_packets(compute_task)  # status: PROCESSING -> IN_BUFFER

                else: 
                    compute_task.generated_packet_count     += 1  
                    compute_task.current_processing_cycle   = 0 

                    if compute_task.generated_packet_count == compute_task.expected_generated_packets:
                        self._update_task_as_complete(compute_task)

                    self._debug_print(
                        f"Generated {compute_task.generated_packet_count}/{compute_task.expected_generated_packets} " 
                        f"packets in task {compute_task.task_id}"
                    )

                    self._check_generate_for_inter_task_dependency(compute_task) 

            else :
                self._debug_print(
                    f"Task {compute_task.task_id} is processing at cycle "
                    f"{compute_task.current_processing_cycle}/{compute_task.processing_cycles}"
                )

    def _empty_output_buffer(self, compute_task: TaskInfo) -> None:
        """
        Used for emptying  the output buffer of the PE in test conditions 
        """
        self.output_network_interface.empty()
        compute_task.generated_packet_count += 1
        print(f"Generated {compute_task.generated_packet_count}/{compute_task.expected_generated_packets} packets of task id {compute_task.task_id}")


    def _move_flits_to_router_buffer(self) -> bool:

        router = self.router_lookup[self.xy]

        if not router.is_local_input_buffer_full():

            self._debug_print(
                f"Moving flits to {router} local input buffer")

            flit = self.output_network_interface.remove()
            self.output_network_interface.fill_emtpy_slots()
            router.add_flit_to_local_input_buffer(flit)

            self._debug_print(f"\t-> {router._local_input_buffer}", with_tag=False)

            if isinstance(flit, TailFlit):
                return True
        
        return False

    def is_input_buffer_full(self) -> bool:
        return self.input_network_interface.is_full()
            

    def _process_trasmit_generate_packets(self, compute_task: TaskInfo) -> Packet:
        """
        Generate the packet for the transmit task  
        The packet is ready for transmit in 1 clock cycle. I.e copied to output_network_interface  
        Status of the task is changed to IN_BUFFER  
        """

        # Popped from the list based on the number of packets required by the task
        assert len(compute_task.transmit_list) > 0, "Transmit id list is empty"

        # Add transmit information here .
        transmit_id         = compute_task.transmit_list[0].id
        transmit_require    = compute_task.transmit_list[0].require
        compute_task.transmit_list[0].count += 1

        packet = Packet(
                    source_xy       = self.xy,
                    dest_id         = transmit_id,
                    source_task_id  = compute_task.task_id
                )
                
        self.output_network_interface.fill_with_packet(packet)
        compute_task.status = TaskStatus.IN_BUFFER

        transmit_count = compute_task.transmit_list[0].count

        if transmit_count == transmit_require:
            self._debug_print(f"Transmitted all packet for task {transmit_id}")
            compute_task.transmit_list.pop(0)

        else: 
            self._debug_print(f"Transmitting {transmit_count}/{transmit_require} packets for task {transmit_id}")


    def _can_generate_packets(self) -> bool:
        output_buffer_full = self.output_network_interface.is_full()    
        return not output_buffer_full
        

    def _process_tasks(self) -> None:
        """
        Checks if multiple tasks are processing at the same time
        Increment the processing cycle for the task (in compute_list) that is processing
        """

        processing_tasks = [task for task in self.compute_list if task.status == TaskStatus.PROCESSING]
        if len(processing_tasks) > 1:
            raise ValueError("Multiple tasks are processing at the same time")

        for compute_task in self.compute_list:
            self._process_compute_task(compute_task)

    def _get_packet_count(self) -> None:
        # print(f"{self}Require List:")
        for compute_task in self.compute_list:
            # print(f"- Task {compute_task.task_id}")
            for require in compute_task.require_list:

                self._debug_print(
                    f"Type {require.require_type_id} "
                    f"({require.received_packet_count}/{require.required_packets})"
                )

    def _check_task_requirements_met(self) -> bool:
        """
        Checks if all the tasks have generated the expected number of packets
        Also checks if the status of the task is done 
        This is useful in the simulate function to get the total cycle count required
        """

        for compute_task in self.compute_list:
            if (compute_task.expected_generated_packets != compute_task.generated_packet_count or

                compute_task.status is not TaskStatus.DONE):
                return False
        
        return True

    def process(self, packet: Optional[Packet]) -> bool:
        """Returns True if the task requirements assigned to the PE is met  
        Arg: packet is for testing purposes 
        """

        if self.compute_list is None:
            return None

        self._increment_processing_cycle()

        if packet is not None: 
            self._recieve_packets(packet)

        if not self.compute_is_busy:
            self._can_start_new_processing()    # status: IDLE     -> PROCESSING
            return None

        if self.compute_is_busy:
            self._process_tasks()               # status: PROCESSING  -> IN_BUFFER or DONE

        if self._check_task_requirements_met(): # stops the simulation now 
            return True

    def get_pos(self) -> tuple[int, int]:
        return self.xy

    def get_status(self) -> bool:
        return self.compute_is_busy

    def __repr__(self) -> str:
        if self.compute_is_busy:
            status = "Computing"
        else: 
            status = "Free"
        return f"[PE{self.xy} {status}] "

if __name__ == "__main__":

    """
    Arguments to pass to ProcessingElement:    
    1. xy: tuple[int, int] - x, y coordinates of the PE
    2. Computing List 
        list[TaskInfo] - List of tasks assigned to the PE

    Receive Conditions 
    1. Single PE recieves packets from one PE                           [x]
        - If receives more than the required packets
            if computing is not busy, start processing
    2. Single PE recieves packets from multiple PEs                     [x]
        - Check for require type [task_id in packet] 
            and require count 
    3. Two tasks assigned to one PE in seuquential order                [x]
    4. Two tasks assigned to one PE in parallel order                   [x]
        - Both tasks require packets from the same PE
        - Both tasks require packets from different PEs
            > Check which task gets all the required packets first. 
            > Start processing the task that gets all the required 
                packets first. 
            > If the other task gets all the required packets 
            before the first 
            > task is done processing, wait for the first task to finish processing
            
    Generate Conditions 
    1. Check 
        if 
            the output port for the PE is busy, 
        else 
            send the packets to the Network Interface
    """

    from .packet import PacketStatus
    import copy 

    # Graph in Thesis Notes Pg. 13
    task_1 = TaskInfo(
        task_id                     = 1, 
        processing_cycles           = 5, 
        expected_generated_packets  = 2, 
        require_list                = [RequireInfo(
                                        require_type_id=0, 
                                        required_packets=3), 
                                       RequireInfo(
                                        require_type_id=2, 
                                        required_packets=2)]
    )

    task_3                          = TaskInfo(
        task_id                     = 3,
        processing_cycles           = 4, 
        expected_generated_packets  = 3,
        require_list                =[RequireInfo(
                                        require_type_id=1, 
                                        required_packets=2)], 
        is_transmit_task            = False, 
    )

    computing_list = [task_1, task_3]

    pe_1 = ProcessingElement((0, 0), computing_list, debug_mode=True, )

    # The Packet (src and dest does not matter for now)
    packet_0 = Packet(
                source_xy       = (0, 0),
                dest_id         = 1,
                source_task_id  = 0)

    packet_2 = Packet(
                source_xy       = (0, 0),
                dest_id         = 1,
                source_task_id  = 2)

    packet_0_1 = copy.deepcopy(packet_0)
    packet_0_2 = copy.deepcopy(packet_0)
    packet_2_1 = copy.deepcopy(packet_2)

    packet_list = [packet_0, packet_0_1,  packet_2, packet_2_1, packet_0_2,]
    current_packet = packet_list.pop(0)  

    max_cycle = 66

    for cycle in range(max_cycle):
        print(f"\n> {cycle}")

        task_is_done = pe_1.process(current_packet)

        # Injecting Packets 
        if not current_packet is None and current_packet.get_status() is PacketStatus.IDLE:
            # IDLE means that the packet has been transmitted
            if len(packet_list) > 0:
                current_packet = packet_list.pop(0)
            else: 
                # if all packets in the packet list have been processed
                #  set the current packet to None to signify that there are no more packets
                current_packet = None

        if task_is_done:
            break

